{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2510329,
          "sourceType": "datasetVersion",
          "datasetId": 1520310
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Sentiment Analysis || LSTM",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahendran180923/News_Senticonomy/blob/main/Sentiment_Analysis_%7C%7C_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "jp797498e_twitter_entity_sentiment_analysis_path = kagglehub.dataset_download('jp797498e/twitter-entity-sentiment-analysis')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "-GHWqeouK0vq"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Howdy 🤠\n",
        "## In this notebook i'll be doing **Sentiment Analysis** with **LSTM (Long short term memory)**\n",
        "### if you aren't familiar with **Sentiment Analysis** : it's the process of identifying and categorizing opinions expressed in a piece of text"
      ],
      "metadata": {
        "id": "Z5abJJVdK0vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anyway enough with the yapping and let's cook 😗\n",
        "\n",
        "<img src='https://uploads.dailydot.com/2024/04/let-him-cook-meme-.jpg?q=65&auto=format&w=1600&ar=2:1&fit=crop' height = 420 width = 620></img>"
      ],
      "metadata": {
        "id": "rpQaMndIK0vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agenda\n",
        "1. [Introduction](#Introduction)\n",
        "2. [Data Preprocessing](#Pre-Processing)\n",
        "3. [Model Training](#Model-Building)\n",
        "4. [Evaluation](#Evaluation)"
      ],
      "metadata": {
        "id": "o9XHHe7IK0vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libs and getting the dataset\n",
        "<a id=\"Introduction\"></a>"
      ],
      "metadata": {
        "id": "lgbsOEvVK0vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:39:47.625562Z",
          "iopub.execute_input": "2025-03-21T18:39:47.626068Z",
          "iopub.status.idle": "2025-03-21T18:39:48.612455Z",
          "shell.execute_reply.started": "2025-03-21T18:39:47.626037Z",
          "shell.execute_reply": "2025-03-21T18:39:48.611555Z"
        },
        "id": "-mzPka0YK0vy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "\n",
        "file_path = r\"/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\"\n",
        "df = pd.read_csv(file_path , header = None ,names=['number' , 'Border' , 'label' , 'message']) # Adjusting the column names"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:45:00.742249Z",
          "iopub.execute_input": "2025-03-21T18:45:00.742593Z",
          "iopub.status.idle": "2025-03-21T18:45:00.90631Z",
          "shell.execute_reply.started": "2025-03-21T18:45:00.742563Z",
          "shell.execute_reply": "2025-03-21T18:45:00.905408Z"
        },
        "id": "bpmu4CBRK0vy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### in this dataset we should build a model that can predict whether the sentence has a -ve or +ve or neutral effect based on the user's messages !"
      ],
      "metadata": {
        "id": "oEP8a0ogK0vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's discover the data and get to know it !"
      ],
      "metadata": {
        "id": "dKuwwqH-K0vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:45:03.284644Z",
          "iopub.execute_input": "2025-03-21T18:45:03.284999Z",
          "iopub.status.idle": "2025-03-21T18:45:03.293347Z",
          "shell.execute_reply.started": "2025-03-21T18:45:03.284972Z",
          "shell.execute_reply": "2025-03-21T18:45:03.292485Z"
        },
        "id": "-0RwADvAK0v0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['label'].value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:45:16.312859Z",
          "iopub.execute_input": "2025-03-21T18:45:16.313179Z",
          "iopub.status.idle": "2025-03-21T18:45:16.325925Z",
          "shell.execute_reply.started": "2025-03-21T18:45:16.313153Z",
          "shell.execute_reply": "2025-03-21T18:45:16.325267Z"
        },
        "id": "7aVhW5KvK0v1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Okay let's drop the Useless columns"
      ],
      "metadata": {
        "id": "6KMMqQ66K0v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Border' , 'number'] , axis=1 , inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:46:47.091375Z",
          "iopub.execute_input": "2025-03-21T18:46:47.091736Z",
          "iopub.status.idle": "2025-03-21T18:46:47.102937Z",
          "shell.execute_reply.started": "2025-03-21T18:46:47.091683Z",
          "shell.execute_reply": "2025-03-21T18:46:47.102036Z"
        },
        "id": "Oy4UHkqcK0v3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape ?\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:49:26.261259Z",
          "iopub.execute_input": "2025-03-21T18:49:26.26156Z",
          "iopub.status.idle": "2025-03-21T18:49:26.266834Z",
          "shell.execute_reply.started": "2025-03-21T18:49:26.261537Z",
          "shell.execute_reply": "2025-03-21T18:49:26.266004Z"
        },
        "id": "u3zKzk7iK0v4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Null values ?\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:48:36.899167Z",
          "iopub.execute_input": "2025-03-21T18:48:36.899447Z",
          "iopub.status.idle": "2025-03-21T18:48:36.915264Z",
          "shell.execute_reply.started": "2025-03-21T18:48:36.899426Z",
          "shell.execute_reply": "2025-03-21T18:48:36.91447Z"
        },
        "id": "_Y7EbMuIK0v4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Drop the null rows !"
      ],
      "metadata": {
        "id": "edx_5P9wK0v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:49:50.46093Z",
          "iopub.execute_input": "2025-03-21T18:49:50.461267Z",
          "iopub.status.idle": "2025-03-21T18:49:50.479496Z",
          "shell.execute_reply.started": "2025-03-21T18:49:50.461243Z",
          "shell.execute_reply": "2025-03-21T18:49:50.478784Z"
        },
        "id": "ytSLzpWVK0v4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:49:53.449343Z",
          "iopub.execute_input": "2025-03-21T18:49:53.44964Z",
          "iopub.status.idle": "2025-03-21T18:49:53.454396Z",
          "shell.execute_reply.started": "2025-03-21T18:49:53.449618Z",
          "shell.execute_reply": "2025-03-21T18:49:53.453725Z"
        },
        "id": "3m92yepwK0v5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://media1.tenor.com/m/UGLkFpDi-vsAAAAC/avada-kedavra.gif' height = 420 width = 620></img>"
      ],
      "metadata": {
        "id": "yLtf8L5uK0v5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### That's good"
      ],
      "metadata": {
        "id": "TOm1IYqwK0v5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing\n",
        "### Now let's start with the **Pre-processing** ⚙️\n",
        "### 1st - LowerCasing text"
      ],
      "metadata": {
        "id": "O2kLaMiQK0v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['message'] = df['message'].str.lower()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:52:39.955656Z",
          "iopub.execute_input": "2025-03-21T18:52:39.956192Z",
          "iopub.status.idle": "2025-03-21T18:52:39.997007Z",
          "shell.execute_reply.started": "2025-03-21T18:52:39.956159Z",
          "shell.execute_reply": "2025-03-21T18:52:39.996135Z"
        },
        "id": "WGBMqTvDK0v6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Removing HTML tags !"
      ],
      "metadata": {
        "id": "wHYMwadHK0v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def remove_html(text):\n",
        "\n",
        "    clean_text = BeautifulSoup(text , 'html.parser')\n",
        "\n",
        "    return clean_text.get_text()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:52:47.986773Z",
          "iopub.execute_input": "2025-03-21T18:52:47.987071Z",
          "iopub.status.idle": "2025-03-21T18:52:48.229231Z",
          "shell.execute_reply.started": "2025-03-21T18:52:47.987048Z",
          "shell.execute_reply": "2025-03-21T18:52:48.22859Z"
        },
        "id": "Nc1iVvM6K0v6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['message'] = df['message'].apply(remove_html)\n",
        "\n",
        "display(df['message'].head(2))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:52:50.98027Z",
          "iopub.execute_input": "2025-03-21T18:52:50.980805Z",
          "iopub.status.idle": "2025-03-21T18:52:53.554084Z",
          "shell.execute_reply.started": "2025-03-21T18:52:50.980773Z",
          "shell.execute_reply": "2025-03-21T18:52:53.553373Z"
        },
        "id": "QSHA8Ea6K0v6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Removing URLs (using regular expression (regex)"
      ],
      "metadata": {
        "id": "Q5FWGTawK0v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_url(text):\n",
        "\n",
        "    return re.sub(r'http\\S+|www\\S+', '', text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:04.132178Z",
          "iopub.execute_input": "2025-03-21T18:53:04.132459Z",
          "iopub.status.idle": "2025-03-21T18:53:04.136372Z",
          "shell.execute_reply.started": "2025-03-21T18:53:04.132437Z",
          "shell.execute_reply": "2025-03-21T18:53:04.135561Z"
        },
        "id": "iRslbLKIK0v7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['message'] = df['message'].apply(clean_url)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:05.983091Z",
          "iopub.execute_input": "2025-03-21T18:53:05.98338Z",
          "iopub.status.idle": "2025-03-21T18:53:06.127836Z",
          "shell.execute_reply.started": "2025-03-21T18:53:05.983359Z",
          "shell.execute_reply": "2025-03-21T18:53:06.127121Z"
        },
        "id": "_9sKfT5HK0v7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 - Removing punctuation"
      ],
      "metadata": {
        "id": "tvtUgfIyK0v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "\n",
        "    return re.sub(r'[^\\w\\s]', '', text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:11.242352Z",
          "iopub.execute_input": "2025-03-21T18:53:11.242642Z",
          "iopub.status.idle": "2025-03-21T18:53:11.24653Z",
          "shell.execute_reply.started": "2025-03-21T18:53:11.242618Z",
          "shell.execute_reply": "2025-03-21T18:53:11.245586Z"
        },
        "id": "F9rd-EJLK0v7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['message'] = df['message'].apply(remove_punctuation)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:13.565464Z",
          "iopub.execute_input": "2025-03-21T18:53:13.565809Z",
          "iopub.status.idle": "2025-03-21T18:53:13.827413Z",
          "shell.execute_reply.started": "2025-03-21T18:53:13.56578Z",
          "shell.execute_reply": "2025-03-21T18:53:13.826749Z"
        },
        "id": "PqkPcMJnK0v7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 - Removing Stop words\n",
        "\n",
        "#### Stop words like : \"the,\" \"is,\" \"and,\" \"in,\" \"on\" don't add much of a value to the model in this task"
      ],
      "metadata": {
        "id": "6zPOBxaiK0v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    if not isinstance(text, str):  # Handle non-string inputs\n",
        "        return text\n",
        "\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.text for token in doc if not token.is_stop])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:22.363772Z",
          "iopub.execute_input": "2025-03-21T18:53:22.364078Z",
          "iopub.status.idle": "2025-03-21T18:53:29.058169Z",
          "shell.execute_reply.started": "2025-03-21T18:53:22.364056Z",
          "shell.execute_reply": "2025-03-21T18:53:29.057477Z"
        },
        "id": "5zD7DA9tK0v8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['message'] = df['message'].apply(remove_stopwords)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T18:53:45.825357Z",
          "iopub.execute_input": "2025-03-21T18:53:45.825997Z",
          "iopub.status.idle": "2025-03-21T19:01:23.616454Z",
          "shell.execute_reply.started": "2025-03-21T18:53:45.825964Z",
          "shell.execute_reply": "2025-03-21T19:01:23.615771Z"
        },
        "id": "8NcozJBgK0v8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:04:16.265598Z",
          "iopub.execute_input": "2025-03-21T19:04:16.265978Z",
          "iopub.status.idle": "2025-03-21T19:04:16.273557Z",
          "shell.execute_reply.started": "2025-03-21T19:04:16.265948Z",
          "shell.execute_reply": "2025-03-21T19:04:16.272604Z"
        },
        "id": "Zf6hcaA8K0v9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 - Removing Emojis !"
      ],
      "metadata": {
        "id": "lNhVypcbK0v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "def remove_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "df['message'] = df['message'].apply(remove_emojis)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:04:31.20478Z",
          "iopub.execute_input": "2025-03-21T19:04:31.205065Z",
          "iopub.status.idle": "2025-03-21T19:04:35.362108Z",
          "shell.execute_reply.started": "2025-03-21T19:04:31.205044Z",
          "shell.execute_reply": "2025-03-21T19:04:35.361202Z"
        },
        "id": "7Q7lv0YqK0v9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7 - Lemmatization\n",
        "#### changing the word back to its roots like : playing -> play , ate -> eat"
      ],
      "metadata": {
        "id": "OD1D7vtRK0v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text):\n",
        "\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "df['message_lemmatized'] = df['message'].apply(lemmatize_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:04:37.782417Z",
          "iopub.execute_input": "2025-03-21T19:04:37.782774Z",
          "iopub.status.idle": "2025-03-21T19:10:54.996105Z",
          "shell.execute_reply.started": "2025-03-21T19:04:37.782733Z",
          "shell.execute_reply": "2025-03-21T19:10:54.995423Z"
        },
        "id": "Csd9dJFlK0v-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:12:47.269892Z",
          "iopub.execute_input": "2025-03-21T19:12:47.270204Z",
          "iopub.status.idle": "2025-03-21T19:12:47.278322Z",
          "shell.execute_reply.started": "2025-03-21T19:12:47.270179Z",
          "shell.execute_reply": "2025-03-21T19:12:47.277469Z"
        },
        "id": "C24sKq3eK0wQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We finished the cleaning part ! Hooray 🥳\n",
        "### now let's put all what we've done to process incoming input in the future !"
      ],
      "metadata": {
        "id": "O-rHec8RK0wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):  # Handle non-string inputs\n",
        "        return text\n",
        "\n",
        "    text = text.lower()  # 1️⃣ Convert to lowercase\n",
        "    text = remove_html(text)  # 2️⃣ Remove HTML\n",
        "    text = clean_url(text)  # 3️⃣ Remove URLs\n",
        "    text = remove_punctuation(text)  # 4️⃣ Remove punctuation\n",
        "    text = remove_stopwords(text)  # 5️⃣ Remove stopwords\n",
        "    text = remove_emojis(text)  # 6️⃣ Remove emojis\n",
        "    text = lemmatize_text(text)  # 7️⃣ Lemmatization\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:12:51.279344Z",
          "iopub.execute_input": "2025-03-21T19:12:51.279627Z",
          "iopub.status.idle": "2025-03-21T19:12:51.284217Z",
          "shell.execute_reply.started": "2025-03-21T19:12:51.279605Z",
          "shell.execute_reply": "2025-03-21T19:12:51.283414Z"
        },
        "id": "K_UVsmo9K0wQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# let's give it a test !\n",
        "\n",
        "new_text = \"Heyyyy!!! 😊 Check this out: https://example.com <b>Awesome!</b>\"\n",
        "cleaned_text = clean_text(new_text)\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:13:04.786258Z",
          "iopub.execute_input": "2025-03-21T19:13:04.786576Z",
          "iopub.status.idle": "2025-03-21T19:13:04.806351Z",
          "shell.execute_reply.started": "2025-03-21T19:13:04.78655Z",
          "shell.execute_reply": "2025-03-21T19:13:04.805537Z"
        },
        "id": "x92LfwZrK0wQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Cloud"
      ],
      "metadata": {
        "id": "FAYKe3ksK0wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Convert the column to a single string\n",
        "text = df['message_lemmatized'].astype(str).str.cat(sep=\" \")\n",
        "\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:16:20.461776Z",
          "iopub.execute_input": "2025-03-21T19:16:20.462101Z",
          "iopub.status.idle": "2025-03-21T19:16:24.765507Z",
          "shell.execute_reply.started": "2025-03-21T19:16:20.462078Z",
          "shell.execute_reply": "2025-03-21T19:16:24.764617Z"
        },
        "id": "JARKpCgeK0wR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now let's a word cloud of the +ve sentences and the -ve according to the data"
      ],
      "metadata": {
        "id": "k_F6fqTzK0wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine text data for each sentiment category\n",
        "positive_text = \" \".join(df[df[\"label\"] == \"Positive\"][\"message_lemmatized\"])\n",
        "negative_text = \" \".join(df[df[\"label\"] == \"Negative\"][\"message_lemmatized\"])\n",
        "neutral_text = \" \".join(df[df[\"label\"] == \"Neutral\"][\"message_lemmatized\"])\n",
        "irrelevant_text = \" \".join(df[df[\"label\"] == \"Irrelevant\"][\"message_lemmatized\"])\n",
        "\n",
        "# Generate word clouds\n",
        "positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)\n",
        "negative_wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='Reds').generate(negative_text)\n",
        "neutral_wordcloud = WordCloud(width=800, height=400, background_color='gray').generate(neutral_text)\n",
        "irrelevant_wordcloud = WordCloud(width=800, height=400, background_color='lightgray').generate(irrelevant_text)\n",
        "\n",
        "# Plot word clouds\n",
        "fig, ax = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "ax[0, 0].imshow(positive_wordcloud, interpolation='bilinear')\n",
        "ax[0, 0].set_title(\"Positive Reviews\")\n",
        "ax[0, 0].axis(\"off\")\n",
        "\n",
        "ax[0, 1].imshow(negative_wordcloud, interpolation='bilinear')\n",
        "ax[0, 1].set_title(\"Negative Reviews\")\n",
        "ax[0, 1].axis(\"off\")\n",
        "\n",
        "ax[1, 0].imshow(neutral_wordcloud, interpolation='bilinear')\n",
        "ax[1, 0].set_title(\"Neutral Reviews\")\n",
        "ax[1, 0].axis(\"off\")\n",
        "\n",
        "ax[1, 1].imshow(irrelevant_wordcloud, interpolation='bilinear')\n",
        "ax[1, 1].set_title(\"Irrelevant Reviews\")\n",
        "ax[1, 1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:25:09.687971Z",
          "iopub.execute_input": "2025-03-21T19:25:09.688269Z",
          "iopub.status.idle": "2025-03-21T19:25:16.630619Z",
          "shell.execute_reply.started": "2025-03-21T19:25:09.688245Z",
          "shell.execute_reply": "2025-03-21T19:25:16.629537Z"
        },
        "id": "f3MitAO2K0wR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## from this word cloud we can remove the word game as it's illogical to exist in every class !"
      ],
      "metadata": {
        "id": "hjHi2FaKK0wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"message_lemmatized\"] = df[\"message_lemmatized\"].str.replace(r'\\bgame\\b', '', regex=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:25:03.951994Z",
          "iopub.execute_input": "2025-03-21T19:25:03.952309Z",
          "iopub.status.idle": "2025-03-21T19:25:04.120869Z",
          "shell.execute_reply.started": "2025-03-21T19:25:03.952285Z",
          "shell.execute_reply": "2025-03-21T19:25:04.12016Z"
        },
        "id": "jXz3nxiDK0wS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing for the Target"
      ],
      "metadata": {
        "id": "cUm-RR0YK0wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm going to mix the neutral class with the Irrelevant\n",
        "df['label'] = df['label'].map({'Positive' : 1 ,  'Negative' : 0 ,'Neutral':2 , 'Irrelevant' : 2 })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:29:09.826979Z",
          "iopub.execute_input": "2025-03-21T19:29:09.827306Z",
          "iopub.status.idle": "2025-03-21T19:29:09.837405Z",
          "shell.execute_reply.started": "2025-03-21T19:29:09.827283Z",
          "shell.execute_reply": "2025-03-21T19:29:09.836719Z"
        },
        "id": "gQ55f5fQK0wS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:29:19.95293Z",
          "iopub.execute_input": "2025-03-21T19:29:19.953257Z",
          "iopub.status.idle": "2025-03-21T19:29:19.961621Z",
          "shell.execute_reply.started": "2025-03-21T19:29:19.953231Z",
          "shell.execute_reply": "2025-03-21T19:29:19.960878Z"
        },
        "id": "NIw7k8wPK0wS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data\n",
        "#### into ( train , test and validation data )\n",
        "#### since that there's imbalance in the target i'm going to use stratified sampling"
      ],
      "metadata": {
        "id": "ytKzokPvK0wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['message_lemmatized'] # feature matrix ( in this case it's just a vectore cause it's only one column)\n",
        "y = df['label'] # target column\n",
        "\n",
        "X_train1 , X_test , y_train1 , y_test = train_test_split(X,y , random_state = 42 , test_size = 0.2  , shuffle = True)\n",
        "X_train , X_val , y_train , y_val = train_test_split(X_train1 , y_train1 , random_state = 42 , test_size = 0.15  , shuffle = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:18.933687Z",
          "iopub.execute_input": "2025-03-21T19:30:18.934011Z",
          "iopub.status.idle": "2025-03-21T19:30:18.956501Z",
          "shell.execute_reply.started": "2025-03-21T19:30:18.933988Z",
          "shell.execute_reply": "2025-03-21T19:30:18.955528Z"
        },
        "id": "e6GlN91qK0wT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape , X_val.shape , X_test.shape , y_train.shape , y_val.shape , y_test.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:20.322252Z",
          "iopub.execute_input": "2025-03-21T19:30:20.322547Z",
          "iopub.status.idle": "2025-03-21T19:30:20.327892Z",
          "shell.execute_reply.started": "2025-03-21T19:30:20.322522Z",
          "shell.execute_reply": "2025-03-21T19:30:20.327249Z"
        },
        "id": "NE64yOuRK0wT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "#### Converting words into numerical tokens"
      ],
      "metadata": {
        "id": "GBjA6X5UK0wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:26:13.788071Z",
          "iopub.execute_input": "2025-03-21T19:26:13.788363Z",
          "iopub.status.idle": "2025-03-21T19:26:24.787483Z",
          "shell.execute_reply.started": "2025-03-21T19:26:13.788343Z",
          "shell.execute_reply": "2025-03-21T19:26:24.786828Z"
        },
        "id": "LWgV17wfK0wU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = 'nothing')\n",
        "tokenizer.fit_on_texts(X_train) # we call this method to build the tokenizer on the train data only to avoid data leakage !"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:23.958328Z",
          "iopub.execute_input": "2025-03-21T19:30:23.958619Z",
          "iopub.status.idle": "2025-03-21T19:30:24.63828Z",
          "shell.execute_reply.started": "2025-03-21T19:30:23.958595Z",
          "shell.execute_reply": "2025-03-21T19:30:24.637608Z"
        },
        "id": "mKfN2XzGK0wU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  returns the total number of documents (sentences) processed by the tokenizer\n",
        "# just to make sure that all the sentences have been converted to tokens !\n",
        "\n",
        "tokenizer.document_count"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:26.007508Z",
          "iopub.execute_input": "2025-03-21T19:30:26.007826Z",
          "iopub.status.idle": "2025-03-21T19:30:26.012583Z",
          "shell.execute_reply.started": "2025-03-21T19:30:26.007802Z",
          "shell.execute_reply": "2025-03-21T19:30:26.011768Z"
        },
        "id": "9YfmOYwqK0wV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversion to sequence\n",
        "#### used to convert each text in the data to sequences of integers based on the tokenizer's vocabulary"
      ],
      "metadata": {
        "id": "emwDQhZcK0wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:27.860751Z",
          "iopub.execute_input": "2025-03-21T19:30:27.861045Z",
          "iopub.status.idle": "2025-03-21T19:30:28.934673Z",
          "shell.execute_reply.started": "2025-03-21T19:30:27.861022Z",
          "shell.execute_reply": "2025-03-21T19:30:28.933974Z"
        },
        "id": "nPfVoAuxK0wV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding\n",
        "#### we apply padding on the data to ensure that each sequence is the same length !"
      ],
      "metadata": {
        "id": "0Ai1wvJvK0wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the max length\n",
        "max_len = max(len(tokens) for tokens in X_train_seq)\n",
        "print(\"Maximum sequence length (maxlen):\", max_len)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:31.334462Z",
          "iopub.execute_input": "2025-03-21T19:30:31.334802Z",
          "iopub.status.idle": "2025-03-21T19:30:31.344489Z",
          "shell.execute_reply.started": "2025-03-21T19:30:31.334775Z",
          "shell.execute_reply": "2025-03-21T19:30:31.343628Z"
        },
        "id": "JHxOSDLmK0wW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Perform padding on X_train and X_test sequences and X_val\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "X_val_padded = pad_sequences(X_val_seq, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:33.478771Z",
          "iopub.execute_input": "2025-03-21T19:30:33.479097Z",
          "iopub.status.idle": "2025-03-21T19:30:33.659099Z",
          "shell.execute_reply.started": "2025-03-21T19:30:33.479071Z",
          "shell.execute_reply": "2025-03-21T19:30:33.658131Z"
        },
        "id": "DaMYoj8qK0wW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the padded sequences for X_train and X_test\n",
        "print(\"X_train_padded:\")\n",
        "print(X_train_padded[:1])\n",
        "print(\"\\nX_test_padded:\")\n",
        "print(X_test_padded[:1])\n",
        "print(\"\\nX_val_padded:\")\n",
        "print(X_val_padded[:1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:35.494456Z",
          "iopub.execute_input": "2025-03-21T19:30:35.494808Z",
          "iopub.status.idle": "2025-03-21T19:30:35.500847Z",
          "shell.execute_reply.started": "2025-03-21T19:30:35.494779Z",
          "shell.execute_reply": "2025-03-21T19:30:35.500156Z"
        },
        "id": "whJX4mDyK0wX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I was plannig to use Glove as a pretrained model for vector embeddings and then finetune it with my data\n",
        "### but let's give training an embedding layer from scratch a try first !\n",
        "### However with what we got so far we can train the model directly but LSTM works well with vector embeddings"
      ],
      "metadata": {
        "id": "Z04P5gAIK0wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define vocab size based on the tokenizer\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:30:38.263507Z",
          "iopub.execute_input": "2025-03-21T19:30:38.263841Z",
          "iopub.status.idle": "2025-03-21T19:30:38.268197Z",
          "shell.execute_reply.started": "2025-03-21T19:30:38.263814Z",
          "shell.execute_reply": "2025-03-21T19:30:38.267356Z"
        },
        "id": "yARYzdzHK0wY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "maEDCgqeK0wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=100),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128 , return_sequences = True , dropout = 0.2 , recurrent_dropout = 0.2)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64 , dropout = 0.2 , recurrent_dropout = 0.2)),\n",
        "    tf.keras.layers.Dense(64 , activation='relu'  , kernel_initializer = 'he_normal'),\n",
        "    tf.keras.layers.Dense(3 , activation = 'softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:32:27.367269Z",
          "iopub.execute_input": "2025-03-21T19:32:27.367581Z",
          "iopub.status.idle": "2025-03-21T19:32:27.39821Z",
          "shell.execute_reply.started": "2025-03-21T19:32:27.367559Z",
          "shell.execute_reply": "2025-03-21T19:32:27.397561Z"
        },
        "id": "jaS1iwcgK0wY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# defining callbacks for Early stopping and changing the learning rate while training\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:32:28.973153Z",
          "iopub.execute_input": "2025-03-21T19:32:28.97344Z",
          "iopub.status.idle": "2025-03-21T19:32:28.977553Z",
          "shell.execute_reply.started": "2025-03-21T19:32:28.973417Z",
          "shell.execute_reply": "2025-03-21T19:32:28.976784Z"
        },
        "id": "u-HtX2X-K0wZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:32:31.093747Z",
          "iopub.execute_input": "2025-03-21T19:32:31.094032Z",
          "iopub.status.idle": "2025-03-21T19:32:31.101867Z",
          "shell.execute_reply.started": "2025-03-21T19:32:31.094012Z",
          "shell.execute_reply": "2025-03-21T19:32:31.101195Z"
        },
        "id": "S-XzywomK0wZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  # Train the Model\n",
        "  history = model.fit(\n",
        "      X_train_padded,\n",
        "      y_train,\n",
        "      validation_data=(X_val_padded, y_val),  # Validation set\n",
        "      batch_size=32,\n",
        "      epochs=30,\n",
        "      callbacks=[early_stopping , reduce_lr],  # to Prevent overfitting\n",
        "      verbose=1\n",
        "  )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T19:32:32.863107Z",
          "iopub.execute_input": "2025-03-21T19:32:32.863394Z",
          "iopub.status.idle": "2025-03-21T22:00:02.316625Z",
          "shell.execute_reply.started": "2025-03-21T19:32:32.863372Z",
          "shell.execute_reply": "2025-03-21T22:00:02.315743Z"
        },
        "id": "AsJimnYQK0wZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:01:55.738324Z",
          "iopub.execute_input": "2025-03-21T22:01:55.738688Z",
          "iopub.status.idle": "2025-03-21T22:01:55.757202Z",
          "shell.execute_reply.started": "2025-03-21T22:01:55.738658Z",
          "shell.execute_reply": "2025-03-21T22:01:55.756513Z"
        },
        "id": "n4WuRRQvK0wZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 4), dpi=150)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:02:00.065404Z",
          "iopub.execute_input": "2025-03-21T22:02:00.065764Z",
          "iopub.status.idle": "2025-03-21T22:02:00.282381Z",
          "shell.execute_reply.started": "2025-03-21T22:02:00.065729Z",
          "shell.execute_reply": "2025-03-21T22:02:00.281575Z"
        },
        "id": "Q63nZSzkK0wa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4), dpi=150)\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:02:07.011335Z",
          "iopub.execute_input": "2025-03-21T22:02:07.011779Z",
          "iopub.status.idle": "2025-03-21T22:02:07.271548Z",
          "shell.execute_reply.started": "2025-03-21T22:02:07.011727Z",
          "shell.execute_reply": "2025-03-21T22:02:07.270488Z"
        },
        "id": "dX4dEgEkK0wa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "y4pM4qfMK0wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model predictions (probabilities)\n",
        "y_probs = model.predict(X_test_padded)\n",
        "\n",
        "# Converting probs into Binary values\n",
        "y_pred = np.argmax(y_probs, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:06:29.477855Z",
          "iopub.execute_input": "2025-03-21T22:06:29.47816Z",
          "iopub.status.idle": "2025-03-21T22:07:09.79283Z",
          "shell.execute_reply.started": "2025-03-21T22:06:29.478138Z",
          "shell.execute_reply": "2025-03-21T22:07:09.792056Z"
        },
        "id": "9gNDK4VSK0wb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:07:19.170311Z",
          "iopub.execute_input": "2025-03-21T22:07:19.170612Z",
          "iopub.status.idle": "2025-03-21T22:08:00.009645Z",
          "shell.execute_reply.started": "2025-03-21T22:07:19.170588Z",
          "shell.execute_reply": "2025-03-21T22:08:00.008959Z"
        },
        "id": "qaChzYBzK0wb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "Vl-qm7Y1K0wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "cfm = confusion_matrix(y_test , y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:11:31.629026Z",
          "iopub.execute_input": "2025-03-21T22:11:31.629333Z",
          "iopub.status.idle": "2025-03-21T22:11:31.63623Z",
          "shell.execute_reply.started": "2025-03-21T22:11:31.629311Z",
          "shell.execute_reply": "2025-03-21T22:11:31.635219Z"
        },
        "id": "VP1MP57pK0wb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# the report\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:11:33.56034Z",
          "iopub.execute_input": "2025-03-21T22:11:33.560663Z",
          "iopub.status.idle": "2025-03-21T22:11:33.585056Z",
          "shell.execute_reply.started": "2025-03-21T22:11:33.560633Z",
          "shell.execute_reply": "2025-03-21T22:11:33.584352Z"
        },
        "id": "p7ZwO-8NK0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cfm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative' , 'Positive' , 'Neutral'], yticklabels=['Negative' , 'Positive','Neutral'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:12:41.252341Z",
          "iopub.execute_input": "2025-03-21T22:12:41.252622Z",
          "iopub.status.idle": "2025-03-21T22:12:41.440396Z",
          "shell.execute_reply.started": "2025-03-21T22:12:41.2526Z",
          "shell.execute_reply": "2025-03-21T22:12:41.439683Z"
        },
        "id": "Tt6TeAdaK0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From the Confusion matrix we can conclude that the model is Okay !"
      ],
      "metadata": {
        "id": "gWY48qnhK0wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://media1.tenor.com/m/xZUiiLfAwzQAAAAC/walter-white-let-him-cook.gif' height = 420 width = 620></img>"
      ],
      "metadata": {
        "id": "eE_gGfeLK0wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model and the tokenizer"
      ],
      "metadata": {
        "id": "45CvBg51K0wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:13:10.268439Z",
          "iopub.execute_input": "2025-03-21T22:13:10.268858Z",
          "iopub.status.idle": "2025-03-21T22:13:10.296485Z",
          "shell.execute_reply.started": "2025-03-21T22:13:10.268823Z",
          "shell.execute_reply": "2025-03-21T22:13:10.295623Z"
        },
        "id": "tYm5UN6vK0we"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# now the model\n",
        "\n",
        "model.save(\"LSTM_Sentiment_analysis.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:13:13.648362Z",
          "iopub.execute_input": "2025-03-21T22:13:13.648675Z",
          "iopub.status.idle": "2025-03-21T22:13:13.762602Z",
          "shell.execute_reply.started": "2025-03-21T22:13:13.648649Z",
          "shell.execute_reply": "2025-03-21T22:13:13.761746Z"
        },
        "id": "rfRhkmJRK0we"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing Pipeline for predictions"
      ],
      "metadata": {
        "id": "8YTuKPCbK0we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(texts, tokenizer):\n",
        "    \"\"\"\n",
        "    Preprocess new incoming text data.\n",
        "\n",
        "    Args:\n",
        "        texts (list of str): List of raw text inputs.\n",
        "        tokenizer (Tokenizer): Pre-trained tokenizer.\n",
        "        max_len (int): Maximum sequence length.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Padded sequences ready for prediction.\n",
        "    \"\"\"\n",
        "    # Convert text to sequences\n",
        "    text_seq = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Apply padding\n",
        "    text_padded = pad_sequences(text_seq, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "    return text_padded"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:13:35.17987Z",
          "iopub.execute_input": "2025-03-21T22:13:35.180191Z",
          "iopub.status.idle": "2025-03-21T22:13:35.184483Z",
          "shell.execute_reply.started": "2025-03-21T22:13:35.180164Z",
          "shell.execute_reply": "2025-03-21T22:13:35.183457Z"
        },
        "id": "NdIT0N4pK0wf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(text , model , tokenizer):\n",
        "\n",
        "    text = [text]\n",
        "    text = clean_text(text)\n",
        "    text_padded =  preprocess_text(text , tokenizer)\n",
        "\n",
        "    y_prob = model.predict(text_padded)\n",
        "\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "    classes = ['Negative' , 'Positive' , 'Neutral']\n",
        "\n",
        "    pred_class = classes[y_pred[0]]  # Get predicted class label\n",
        "    pred_prob = y_prob[0][y_pred[0]] # get predicted prob\n",
        "\n",
        "\n",
        "    return pred_class, pred_prob"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:16:55.777675Z",
          "iopub.execute_input": "2025-03-21T22:16:55.778047Z",
          "iopub.status.idle": "2025-03-21T22:16:55.782977Z",
          "shell.execute_reply.started": "2025-03-21T22:16:55.778019Z",
          "shell.execute_reply": "2025-03-21T22:16:55.781942Z"
        },
        "id": "aFu_a2oPK0wf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model\n",
        "## Now if u want to use the model again without training it again\n",
        "### you can simply load it with the tokenzier"
      ],
      "metadata": {
        "id": "LxnE7Ho_K0wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the tokenizer\n",
        "\n",
        "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model('/kaggle/working/LSTM_Sentiment_analysis.h5')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:13:41.941935Z",
          "iopub.execute_input": "2025-03-21T22:13:41.942383Z",
          "iopub.status.idle": "2025-03-21T22:13:42.571061Z",
          "shell.execute_reply.started": "2025-03-21T22:13:41.942341Z",
          "shell.execute_reply": "2025-03-21T22:13:42.570135Z"
        },
        "id": "ejTGqsWzK0wg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I'm Sad\"\n",
        "\n",
        "pred_class  , prob  = Predict(new_text , loaded_model , tokenizer)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:24:28.335658Z",
          "iopub.execute_input": "2025-03-21T22:24:28.335992Z",
          "iopub.status.idle": "2025-03-21T22:24:28.483892Z",
          "shell.execute_reply.started": "2025-03-21T22:24:28.335967Z",
          "shell.execute_reply": "2025-03-21T22:24:28.48318Z"
        },
        "id": "jAnJTjKEK0wg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Class Prediction is : {pred_class} with Probabilty {prob}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T22:24:30.216783Z",
          "iopub.execute_input": "2025-03-21T22:24:30.217077Z",
          "iopub.status.idle": "2025-03-21T22:24:30.221384Z",
          "shell.execute_reply.started": "2025-03-21T22:24:30.217054Z",
          "shell.execute_reply": "2025-03-21T22:24:30.220493Z"
        },
        "id": "2JOXArwyK0wg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}